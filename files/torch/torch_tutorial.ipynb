{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 6.9410e-310  1.4917e-154   0.0000e+00\n",
       "  1.3956e-75   0.0000e+00   9.9513e-43\n",
       "  0.0000e+00  7.9979e+169   0.0000e+00\n",
       " 6.9534e-309   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- basic operands\n",
    "a = torch.Tensor(5, 3)  -- construct a 5x3 matrix unintialized\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5057  0.8245  0.7690\n",
       " 0.0318  0.3256  0.8298\n",
       " 0.9671  0.1232  0.2564\n",
       " 0.4767  0.0911  0.3251\n",
       " 0.1802  0.4645  0.0414\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.5327  1.6127  1.0020  0.7498\n",
       " 1.0899  0.8610  0.5248  0.2789\n",
       " 0.5520  0.9612  0.3875  1.0297\n",
       " 0.4929  0.6310  0.2775  0.5648\n",
       " 0.4552  0.5796  0.4184  0.2090\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- three ways of doing multiplication\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.5327  1.6127  1.0020  0.7498\n",
       " 1.0899  0.8610  0.5248  0.2789\n",
       " 0.5520  0.9612  0.3875  1.0297\n",
       " 0.4929  0.6310  0.2775  0.5648\n",
       " 0.4552  0.5796  0.4184  0.2090\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = torch.zeros(5, 4)\n",
    "c:mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 5]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--- concatenation\n",
    "torch.cat(torch.ones(3), torch.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cat(torch.ones(3, 2), torch.zeros(2, 2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1  0  0  0\n",
       " 1  1  0  0  0\n",
       " 1  1  0  0  0\n",
       "[torch.DoubleTensor of size 3x5]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.ones(3, 2), torch.zeros(3, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- neural networks\n",
    "-- linear module\n",
    "require 'nn';\n",
    "lin = nn.Linear(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Linear(5 -> 3)\n",
       "{\n",
       "  gradBias : DoubleTensor - size: 3\n",
       "  weight : DoubleTensor - size: 3x5\n",
       "  _type : torch.DoubleTensor\n",
       "  output : DoubleTensor - empty\n",
       "  gradInput : DoubleTensor - empty\n",
       "  bias : DoubleTensor - size: 3\n",
       "  gradWeight : DoubleTensor - size: 3x5\n",
       "}\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.1784  0.2629 -0.0544 -0.3481 -0.3550\n",
       " 0.2463 -0.2964  0.2082 -0.0777  0.2965\n",
       "-0.3059  0.3679 -0.2043 -0.1491  0.0166\n",
       "[torch.DoubleTensor of size 3x5]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- forward pass\n",
    "x = torch.rand(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1520\n",
       " 0.3172\n",
       "-0.0344\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lin:forward(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1520\n",
       " 0.3172\n",
       "-0.0344\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight * x + lin.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.DoubleTensor of size 3x5]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- backward pass\n",
    "lin:zeroGradParameters()\n",
    "print(lin.gradWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1\n",
       " 1\n",
       "-1\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = torch.ones(3):mul(-1)\n",
    "grad[2] = 1\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.3739\n",
       "-0.9272\n",
       " 0.4668\n",
       " 0.4196\n",
       " 0.6349\n",
       "[torch.DoubleTensor of size 5]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin:backward(x, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lin.gradWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- manual gradient descent\n",
    "lin.weight:add(0.1*lin.gradWeight)\n",
    "lin.bias:add(0.1*lin.gradBias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4520\n",
       " 0.6171\n",
       "-0.3343\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin:forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- more complicated networks\n",
    "-- with package 'nn'\n",
    "net = nn.Sequential();\n",
    "net:add(nn.Linear(20, 10));\n",
    "net:add(nn.Tanh());\n",
    "net:add(nn.Linear(10, 10));\n",
    "net:add(nn.Tanh());\n",
    "net:add(nn.Linear(10, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2079\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(20)\n",
    "y1 = net:forward(x)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- with package 'nngraph'\n",
    "require 'nngraph';\n",
    "g1 = - nn.Linear(20, 10)\n",
    "\n",
    "g2 = g1\n",
    "   - nn.Tanh()\n",
    "   - nn.Linear(10, 10)\n",
    "   - nn.Tanh()\n",
    "   - nn.Linear(10, 1)\n",
    "gnet = nn.gModule({g1}, {g2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- fancy network\n",
    "input = - nn.Identity()\n",
    "L1 = input\n",
    "   - nn.Linear(10, 20)\n",
    "   - nn.Tanh()\n",
    "L2 = {input, L1}\n",
    "   - nn.JoinTable(1)\n",
    "   - nn.Linear(30, 60)\n",
    "   - nn.Tanh()\n",
    "L3 = {L1, L2}\n",
    "   - nn.JoinTable(1)\n",
    "   - nn.Linear(80, 1)\n",
    "   - nn.Tanh()\n",
    "g = nn.gModule({input},{L3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'pretty-nn'\n",
    "graph.dot(g.fg, 'fancy', 'fancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1599\n",
       "   11\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 1599\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- training --\n",
    "-- load serialized preprocessed data\n",
    "xx, yy = unpack(torch.load(\"redwine-quality.torch\"))\n",
    "print(xx:size())\n",
    "print(yy:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manualSeed(1234)\n",
    "-- build the network\n",
    "g1 = - nn.Linear(11, 11)\n",
    "g2 = g1\n",
    "   - nn.Tanh()\n",
    "   - nn.Linear(11, 11)\n",
    "   - nn.Tanh()\n",
    "   - nn.Linear(11, 1)\n",
    "winenet = nn.gModule({g1}, {g2})\n",
    "-- mean square error\n",
    "loss = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at epoch\t1\tavg loss\t0.01004729150127\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t2\tavg loss\t0.0052290742312656\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t3\tavg loss\t0.0049271944192332\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t4\tavg loss\t0.0047921190128562\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t5\tavg loss\t0.0047070290363173\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t6\tavg loss\t0.0046433421289942\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t7\tavg loss\t0.0046036616283334\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t8\tavg loss\t0.0045714431047861\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t9\tavg loss\t0.004543280727934\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "at epoch\t10\tavg loss\t0.0045181197352359\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- train!\n",
    "require 'optim';\n",
    "n_epoches = 10\n",
    "n_examples = xx:size(1)\n",
    "\n",
    "W, gradW = winenet:getParameters()\n",
    "optimState = {}\n",
    "\n",
    "for epoch = 1, n_epoches do\n",
    "   local total_loss = 0\n",
    "   for i=1, n_examples do\n",
    "     x = xx[i]\n",
    "     y = torch.Tensor({yy[i]})\n",
    "     winenet:zeroGradParameters()\n",
    "     function feval()\n",
    "        local predicted = winenet:forward(x)\n",
    "        local L = loss:forward(predicted, y)\n",
    "        total_loss = total_loss + L\n",
    "        local dL_dy = loss:backward(predicted, y)\n",
    "        winenet:backward(x, dL_dy) -- computes and updates gradW\n",
    "        return L, gradW\n",
    "     end\n",
    "     optim.adadelta(feval, W, optimState)\n",
    "   end\n",
    "   print('at epoch', epoch, 'avg loss', total_loss/n_examples)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- RNN\n",
    "-- stepwise function\n",
    "ht1 = - nn.Identity()\n",
    "xt = - nn.Identity()\n",
    "ht = {ht1, xt} \n",
    "   - nn.JoinTable(1)\n",
    "   - nn.Linear(20, 10)\n",
    "   - nn.Tanh()\n",
    "stepfunction = nn.gModule({ht1, xt}, {ht})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- build clones\n",
    "\n",
    "function share_params(cell, src)\n",
    "  if torch.type(cell) == 'nn.gModule' then\n",
    "    for i = 1, #cell.forwardnodes do\n",
    "      local node = cell.forwardnodes[i]\n",
    "      if node.data.module then\n",
    "        node.data.module:share(src.forwardnodes[i].data.module,\n",
    "                               'weight', 'bias', 'gradWeight', 'gradBias')\n",
    "      end\n",
    "    end\n",
    "  elseif torch.isTypeOf(cell, 'nn.Module') then\n",
    "    cell:share(src, 'weight', 'bias', 'gradWeight', 'gradBias')\n",
    "  else\n",
    "    error('parameters cannot be shared for this input')\n",
    "  end\n",
    "end\n",
    "\n",
    "-- getParameters() must be called before cloning, \n",
    "-- since getParameters() function will reallocate memory for W and gradW\n",
    "-- the pointers in clones created before getParameters() will not be valid\n",
    "-- after calling this function\n",
    "W, gradW = stepfunction:getParameters()\n",
    "\n",
    "clones = {}\n",
    "N = 100\n",
    "for i = 1, N do\n",
    "    clones[i] = stepfunction:clone()\n",
    "    share_params(clones[i], stepfunction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "h0 = torch.rand(10)\n",
    "x = torch.rand(n, 10)\n",
    "h = torch.zeros(n+1, 10)\n",
    "\n",
    "W:uniform(-1, 1)\n",
    "\n",
    "-- forward\n",
    "h[1] = h0\n",
    "for i = 1, n do\n",
    "    h[i+1] = clones[i]:forward{h[i], x[i]}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5982  0.7899  0.1065  0.3861  0.2972  0.9791  0.0584  0.2194  0.6213  0.0929\n",
       "-0.8879  0.9448 -0.9973  0.2613 -0.6036  0.8370  0.9533  0.2834 -0.9841 -0.9885\n",
       "-0.9585 -0.8517 -0.9440  0.9861  0.7925  0.9844 -0.4312  0.9621 -0.9957 -0.7714\n",
       "-0.9906 -0.9941 -0.6195  0.9659 -0.7310  0.4731  0.5748 -0.6886 -0.9582 -0.9616\n",
       " 0.2694 -0.9459  0.4245  0.9859 -0.8624  0.9984 -0.4313  0.6631 -0.6663 -0.9247\n",
       "-0.9560 -0.2291  0.7429  0.7207  0.8395  0.8807  0.7682 -0.9345 -0.9656 -0.9701\n",
       "-0.6979 -0.8491 -0.9684  0.5480 -0.4236  0.9153  0.9843 -0.5267 -0.4332 -0.9978\n",
       "-0.4794 -0.7863 -0.6081  0.9659  0.3993  0.9734 -0.2141  0.8281 -0.9948 -0.8532\n",
       "[torch.DoubleTensor of size 8x10]\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- before backward\n",
    "-- clean grad weights\n",
    "stepfunction:zeroGradParameters()\n",
    "print(gradW:norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- backward\n",
    "\n",
    "grad_h = torch.zeros(h:size())\n",
    "grad_h[n+1] = torch.rand(10)\n",
    "for i = n, 1, -1 do\n",
    "    local grads = clones[i]:backward({h[i], x[i]}, grad_h[i+1])\n",
    "    grad_h[i], grad_xi = unpack(grads)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0485 -0.0076 -0.1426 -0.1481  0.2058 -0.3213  0.0837 -0.1005  0.1704 -0.0184\n",
       " 0.1845 -0.0528 -0.0360 -0.1501 -0.2151  0.0847  0.2186  0.1488 -0.0878  0.0359\n",
       "-0.2914  0.2014  0.1656  0.1997  0.3198  0.1600 -0.1599  0.0092  0.1554  0.3294\n",
       " 0.2680 -0.1166 -0.4199 -0.0612 -0.2679 -0.1568  0.1995 -0.0984  0.0512 -0.2923\n",
       " 0.0193  0.0260  0.4646 -0.0356 -0.1129  0.4859 -0.0190  0.4001 -0.4585  0.2868\n",
       "-0.0027  0.0779 -0.3206 -0.1302  1.1846 -1.5339 -0.7444 -0.8610  0.8834 -0.2304\n",
       "-0.1865  0.0984  0.7338 -0.7272 -1.1351  0.1258  1.1297  0.3235  0.4508  0.2306\n",
       " 0.8840  0.9886  0.5671  0.0696  0.9945  0.0574  0.1787  0.8679  0.0122  0.8638\n",
       "[torch.DoubleTensor of size 8x10]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grad_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4113012786391\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gradW:norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
